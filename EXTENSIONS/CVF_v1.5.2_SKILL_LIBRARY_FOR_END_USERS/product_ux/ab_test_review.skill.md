# A/B Test Review

> **Domain:** Product & UX  
> **Difficulty:** Medium  
> **CVF Version:** v1.5.2  
> **Inspired by:** antigravity-awesome-skills/ab-testing

## ğŸ¯ Má»¥c Ä‘Ã­ch

ÄÃ¡nh giÃ¡ thiáº¿t káº¿ vÃ  káº¿t quáº£ cá»§a A/B test. Äáº£m báº£o test Ä‘Æ°á»£c setup Ä‘Ãºng cÃ¡ch vÃ  káº¿t quáº£ cÃ³ statistical significance.

**Khi nÃ o nÃªn dÃ¹ng:**
- TrÆ°á»›c khi launch A/B test má»›i
- PhÃ¢n tÃ­ch káº¿t quáº£ sau khi test xong
- Review test design tá»« team
- Quyáº¿t Ä‘á»‹nh scale hay kill variant

---

## ğŸ“‹ Form Input

| Field | Báº¯t buá»™c | MÃ´ táº£ |
|-------|----------|-------|
| **TÃªn Test** | âœ… | MÃ´ táº£ ngáº¯n experiment |
| **Hypothesis** | âœ… | "Náº¿u... thÃ¬... vÃ¬..." |
| **Metric chÃ­nh (OKR)** | âœ… | Conversion, Revenue, Engagement, etc. |
| **Control vs Variant** | âœ… | MÃ´ táº£ sá»± khÃ¡c biá»‡t |
| **Sample Size** | âŒ | Sá»‘ users trong má»—i variant |
| **Duration** | âŒ | Thá»i gian cháº¡y test |
| **Results Data** | âŒ | Conversion rates, uplift % |

---

## âœ… Checklist TrÆ°á»›c khi Test

### Hypothesis Quality
- [ ] Hypothesis cÃ³ clear vÃ  testable?
- [ ] CÃ³ "Why" - lÃ½ do expect change?
- [ ] CÃ³ measurable outcome?
- [ ] CÃ³ reasonable timeframe?

### Test Design
- [ ] Chá»‰ test 1 biáº¿n duy nháº¥t (isolated)?
- [ ] Sample size Ä‘á»§ lá»›n cho statistical power?
- [ ] User assignment random vÃ  fair?
- [ ] No selection bias trong audience?

### Metrics
- [ ] Primary metric cÃ³ Ä‘Æ°á»£c define rÃµ?
- [ ] CÃ³ secondary/guardrail metrics?
- [ ] Tracking Ä‘Ã£ implement vÃ  test?
- [ ] Baseline data cÃ³ sáºµn?

### Technical Setup
- [ ] No bugs/errors trong variant?
- [ ] ÄÃ£ QA test cáº£ control vÃ  variant?
- [ ] Tracking events fire Ä‘Ãºng?
- [ ] No audience overlap vá»›i tests khÃ¡c?

---

## âœ… Checklist Review Results

### Statistical Validity
- [ ] Sample size Ä‘á»§ (power â‰¥80%)?
- [ ] Statistical significance (p < 0.05)?
- [ ] Confidence interval cÃ³ narrow?
- [ ] ÄÃ£ cháº¡y Ä‘á»§ lÃ¢u (â‰¥ 1-2 business cycles)?

### Result Interpretation
- [ ] Effect size cÃ³ meaningful (>5%)?
- [ ] Results consistent across segments?
- [ ] No novelty effect (stable over time)?
- [ ] Guardrail metrics khÃ´ng bá»‹ áº£nh hÆ°á»Ÿng xáº¥u?

### Next Steps
- [ ] CÃ³ clear recommendation (ship/iterate/kill)?
- [ ] Learnings Ä‘Æ°á»£c documented?
- [ ] Follow-up tests Ä‘Æ°á»£c plan?

---

## âš ï¸ Lá»—i ThÆ°á»ng Gáº·p

| Lá»—i | Impact | Fix |
|-----|--------|-----|
| **Peeking early** | False positives | Wait for full sample size |
| **Too many variants** | Diluted power | Max 2-3 variants |
| **Testing too many things** | Unclear learnings | One change at a time |
| **Too short duration** | Novelty effect | Min 2 weeks |
| **Wrong metric** | Misleading results | Focus on business outcome |
| **Ignoring segments** | Miss insights | Segment analysis |
| **No hypothesis** | Random testing | Start with "why" |

---

## ğŸ’¡ Tips & Examples

### Hypothesis Template:
```
If we [CHANGE],
then [METRIC] will [INCREASE/DECREASE] by [X%],
because [REASONING].

Example:
"If we add trust badges on checkout page,
then conversion rate will increase by 5%,
because users feel more secure about payment."
```

### Sample Size Calculator:
```
Minimum sample per variant:
- Small effect (5%): ~3,000 users
- Medium effect (10%): ~800 users
- Large effect (20%): ~200 users

(Assuming baseline 5% conversion, 80% power, 95% confidence)
```

### Duration Guidelines:
| Traffic | Minimum Duration |
|---------|-----------------|
| High (10k+/day) | 1-2 weeks |
| Medium (1k/day) | 2-4 weeks |
| Low (<1k/day) | 4+ weeks |

### Reading Results:
```
âœ… WINNER if:
- p-value < 0.05 (95% confidence)
- Uplift > 5% (practical significance)
- Consistent over time
- No negative guardrail impact

âŒ LOSER if:
- Significant negative effect
- Negative guardrail impact
- Segment analysis shows harm

ğŸ¤· INCONCLUSIVE if:
- No statistical significance
- Sample too small
- Mixed results across segments
```

---

## ğŸ“¤ Expected Output tá»« AI

Khi paste spec nÃ y vÃ o AI, báº¡n sáº½ nháº­n Ä‘Æ°á»£c:

1. **Test Assessment** - Overall quality rating
2. **Hypothesis Review** - Clarity vÃ  testability
3. **Sample Size Check** - Power analysis
4. **Results Analysis** - Statistical interpretation
5. **Segment Analysis** - Breakdown by user types
6. **Recommendation** - Ship / Iterate / Kill
7. **Next Steps** - Follow-up experiments

---

*CVF Skill Library v1.5.2 | Product & UX Domain*
