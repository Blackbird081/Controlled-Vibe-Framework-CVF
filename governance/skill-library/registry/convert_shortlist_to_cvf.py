#!/usr/bin/env python3
"""
Convert SkillsMP shortlist into CVF skill files (v1.5.2 library).

Rules:
- CVF is the canonical base.
- Avoid duplicate repos (one skill per repo).
- For near-duplicates, prefer richer descriptions.
- Generate CVF-compliant .skill.md files with required sections.
"""

from __future__ import annotations

import argparse
import json
import re
from collections import defaultdict
from dataclasses import dataclass
from datetime import date, datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from urllib.parse import urlparse


ROOT_DIR = Path(__file__).resolve().parents[3]
SHORTLIST_PATH = ROOT_DIR / "governance" / "skill-library" / "registry" / "external-sources" / "skillsmp" / "skillsmp_shortlist.json"
SKILL_ROOT = ROOT_DIR / "EXTENSIONS" / "CVF_v1.5.2_SKILL_LIBRARY_FOR_END_USERS"
MAP_OUTPUT = ROOT_DIR / "governance" / "skill-library" / "registry" / "external-sources" / "skillsmp" / "skillsmp_to_cvf_map.md"
EXTERNAL_INDEX_PATH = ROOT_DIR / "governance" / "skill-library" / "registry" / "external-sources" / "index.json"

TODAY = date(2026, 2, 7)

DOMAIN_RISK_MAP = {
    "ai_ml_evaluation": "R1",
    "app_development": "R1",
    "business_analysis": "R1",
    "content_creation": "R0",
    "finance_analytics": "R2",
    "hr_operations": "R2",
    "legal_contracts": "R2",
    "marketing_seo": "R1",
    "product_ux": "R1",
    "security_compliance": "R2",
    "technical_review": "R1",
    "web_development": "R1",
}

DOMAIN_PHASES_MAP = {
    "ai_ml_evaluation": "Discovery, Design, Review",
    "app_development": "Discovery, Design, Build",
    "business_analysis": "Discovery",
    "content_creation": "Discovery, Design",
    "finance_analytics": "Discovery, Review",
    "hr_operations": "Discovery, Review",
    "legal_contracts": "Discovery, Review",
    "marketing_seo": "Discovery, Design",
    "product_ux": "Discovery, Design, Review",
    "security_compliance": "Design, Review",
    "technical_review": "Build, Review",
    "web_development": "Design, Build",
}

DOMAIN_EXAMPLES: Dict[str, Dict[str, object]] = {
    "app_development": {
        "objective": "Thiáº¿t káº¿ API cho á»©ng dá»¥ng quáº£n lÃ½ dá»± Ã¡n",
        "context": "Team 4 dev, cáº§n MVP trong 6 tuáº§n",
        "constraints": "Giá»¯ stack Node/React, Æ°u tiÃªn scale",
        "findings": [
            "Thiáº¿u tiÃªu chÃ­ phÃ¢n ranh quyá»n truy cáº­p",
            "Luá»“ng dá»¯ liá»‡u chÆ°a cÃ³ chuáº©n versioning",
            "Thiáº¿u quy Æ°á»›c error handling thá»‘ng nháº¥t",
        ],
    },
    "web_development": {
        "objective": "Thiáº¿t káº¿ kiáº¿n trÃºc web app cho há»‡ thá»‘ng bÃ¡o cÃ¡o",
        "context": "User 5k/ngÃ y, dashboard cáº­p nháº­t theo giá»",
        "constraints": "Æ¯u tiÃªn tá»‘c Ä‘á»™ táº£i vÃ  cache",
        "findings": [
            "Thiáº¿u phÃ¢n tÃ¡ch layer dá»¯ liá»‡u vÃ  UI",
            "ChÆ°a cÃ³ chiáº¿n lÆ°á»£c caching rÃµ rÃ ng",
            "Thiáº¿u kiá»ƒm soÃ¡t performance trÃªn mobile",
        ],
    },
    "ai_ml_evaluation": {
        "objective": "ÄÃ¡nh giÃ¡ prompt cho chatbot CSKH",
        "context": "Dá»¯ liá»‡u há»™i thoáº¡i Ä‘a ngÃ nh, cáº§n Ä‘o Ä‘á»™ chÃ­nh xÃ¡c",
        "constraints": "KhÃ´ng lÆ°u dá»¯ liá»‡u nháº¡y cáº£m",
        "findings": [
            "Thiáº¿u tiÃªu chÃ­ Ä‘Ã¡nh giÃ¡ nháº¥t quÃ¡n",
            "ChÆ°a cÃ³ benchmark máº«u theo domain",
            "Output chÆ°a gáº¯n vá»›i KPI cháº¥t lÆ°á»£ng",
        ],
    },
    "business_analysis": {
        "objective": "PhÃ¢n tÃ­ch chiáº¿n lÆ°á»£c má»Ÿ rá»™ng thá»‹ trÆ°á»ng",
        "context": "SME Viá»‡t, ngÃ¢n sÃ¡ch 50k USD",
        "constraints": "Dá»¯ liá»‡u thá»‹ trÆ°á»ng háº¡n cháº¿",
        "findings": [
            "Giáº£ Ä‘á»‹nh thá»‹ trÆ°á»ng chÆ°a Ä‘Æ°á»£c xÃ¡c thá»±c",
            "Thiáº¿u so sÃ¡nh rá»§i ro theo ká»‹ch báº£n",
            "ChÆ°a cÃ³ KPI Ä‘o hiá»‡u quáº£ triá»ƒn khai",
        ],
    },
    "content_creation": {
        "objective": "XÃ¢y dá»±ng series blog onboarding cho SaaS",
        "context": "Sáº£n pháº©m B2B, táº­p trung chuyá»ƒn Ä‘á»•i trial",
        "constraints": "Giá»¯ brand voice hiá»‡n cÃ³",
        "findings": [
            "ThÃ´ng Ä‘iá»‡p giÃ¡ trá»‹ chÆ°a nháº¥t quÃ¡n",
            "Thiáº¿u call-to-action theo tá»«ng bÃ i",
            "ChÆ°a cÃ³ guideline tone/format thá»‘ng nháº¥t",
        ],
    },
    "marketing_seo": {
        "objective": "Audit SEO cho landing page sáº£n pháº©m",
        "context": "Traffic 30k/thÃ¡ng, conversion tháº¥p",
        "constraints": "KhÃ´ng Ä‘á»•i domain, chá»‰ tá»‘i Æ°u on-page",
        "findings": [
            "Thiáº¿u cáº¥u trÃºc heading logic",
            "Meta description chÆ°a bÃ¡m keyword",
            "Tá»‘c Ä‘á»™ táº£i trang chÆ°a Ä‘áº¡t chuáº©n",
        ],
    },
    "product_ux": {
        "objective": "Thiáº¿t káº¿ flow onboarding cho mobile app",
        "context": "NgÆ°á»i dÃ¹ng má»›i rÆ¡i nhiá»u á»Ÿ bÆ°á»›c 2",
        "constraints": "Giá»¯ nguyÃªn core feature",
        "findings": [
            "Thiáº¿u bÆ°á»›c giáº£i thÃ­ch giÃ¡ trá»‹ trÆ°á»›c khi Ä‘Äƒng kÃ½",
            "Luá»“ng hiá»‡n quÃ¡ dÃ i, chÆ°a cÃ³ skip option",
            "ChÆ°a cÃ³ thá»­ nghiá»‡m A/B cho báº£n má»›i",
        ],
    },
    "finance_analytics": {
        "objective": "PhÃ¢n tÃ­ch cash flow 6 thÃ¡ng",
        "context": "Startup SaaS Ä‘ang Ä‘á»‘t tiá»n cao",
        "constraints": "Dá»¯ liá»‡u káº¿ toÃ¡n chÆ°a chuáº©n hÃ³a",
        "findings": [
            "Chi phÃ­ váº­n hÃ nh tÄƒng nhanh theo quÃ½",
            "ChÆ°a cÃ³ dá»± bÃ¡o dÃ²ng tiá»n theo ká»‹ch báº£n",
            "Thiáº¿u kiá»ƒm soÃ¡t churn áº£nh hÆ°á»Ÿng doanh thu",
        ],
    },
    "legal_contracts": {
        "objective": "Review NDA cho há»£p tÃ¡c Ä‘á»‘i tÃ¡c",
        "context": "Äá»‘i tÃ¡c quá»‘c táº¿, thá»i háº¡n 12 thÃ¡ng",
        "constraints": "KhÃ´ng thay Ä‘á»•i Ä‘iá»u khoáº£n core",
        "findings": [
            "Pháº¡m vi báº£o máº­t chÆ°a rÃµ rÃ ng",
            "Thiáº¿u Ä‘iá»u khoáº£n xá»­ lÃ½ vi pháº¡m",
            "KhÃ´ng nÃªu rÃµ quyá»n sá»Ÿ há»¯u IP",
        ],
    },
    "hr_operations": {
        "objective": "Viáº¿t JD cho vá»‹ trÃ­ Product Manager",
        "context": "CÃ´ng ty scale nhanh, team 10 ngÆ°á»i",
        "constraints": "Æ¯u tiÃªn á»©ng viÃªn cÃ³ background SaaS",
        "findings": [
            "TiÃªu chÃ­ Ä‘áº§u vÃ o chÆ°a Ä‘o lÆ°á»ng Ä‘Æ°á»£c",
            "Thiáº¿u mÃ´ táº£ trÃ¡ch nhiá»‡m theo KPI",
            "ChÆ°a nÃªu rÃµ lá»™ trÃ¬nh phÃ¡t triá»ƒn",
        ],
    },
    "security_compliance": {
        "objective": "Audit báº£o máº­t cho API gateway",
        "context": "Há»‡ thá»‘ng nhiá»u microservices",
        "constraints": "KhÃ´ng downtime",
        "findings": [
            "Thiáº¿u kiá»ƒm soÃ¡t rate-limit theo tenant",
            "ChÆ°a cÃ³ log/trace Ä‘áº§y Ä‘á»§ cho audit",
            "ChÃ­nh sÃ¡ch token rotation chÆ°a rÃµ",
        ],
    },
    "technical_review": {
        "objective": "Review PR cho flow xÃ¡c thá»±c",
        "context": "Repo lá»›n, nhiá»u contributor",
        "constraints": "KhÃ´ng Ä‘á»•i logic cá»‘t lÃµi",
        "findings": [
            "Thiáº¿u test cho edge cases",
            "ChÆ°a cÃ³ logging cho lá»—i auth",
            "KhÃ´ng cÃ³ guideline rollback",
        ],
    },
}

RISK_AUTONOMY = {
    "R0": "Auto",
    "R1": "Auto + Audit",
    "R2": "Human confirmation required",
    "R3": "Suggest-only",
    "R4": "Blocked",
}


@dataclass
class SkillCandidate:
    name: str
    description: str
    source: str
    cvf_domain: str
    score: float
    matched_query: str
    repo_key: str
    raw: Dict[str, object]


def load_shortlist(path: Path) -> List[Dict[str, object]]:
    payload = json.loads(path.read_text(encoding="utf-8"))
    return payload.get("skills", [])


def normalize_name(value: str) -> str:
    value = value.lower().strip()
    value = re.sub(r"[^a-z0-9]+", "_", value)
    return value.strip("_")


def repo_key_from_source(source: str) -> str:
    if not source:
        return ""
    parsed = urlparse(source)
    if parsed.netloc and "github.com" in parsed.netloc.lower():
        parts = [p for p in parsed.path.split("/") if p]
        if len(parts) >= 2:
            return f"{parts[0].lower()}/{parts[1].lower()}"
    match = re.search(r"github\\.com/([^/]+)/([^/]+)", source, re.IGNORECASE)
    if match:
        return f"{match.group(1).lower()}/{match.group(2).lower()}"
    return source.split("?")[0].lower()


def external_key_for_skill(source: str, name: str) -> str:
    repo_key = repo_key_from_source(source)
    if repo_key:
        return repo_key
    name_key = normalize_name(name)
    if name_key:
        return f"name:{name_key}"
    return ""


def choose_best(candidates: List[SkillCandidate]) -> SkillCandidate:
    candidates.sort(key=lambda x: (len(x.description or ""), x.score), reverse=True)
    return candidates[0]


def dedupe_candidates(candidates: List[SkillCandidate]) -> List[SkillCandidate]:
    by_repo: Dict[str, List[SkillCandidate]] = defaultdict(list)
    for cand in candidates:
        by_repo[cand.repo_key or cand.name.lower()].append(cand)

    chosen = [choose_best(group) for group in by_repo.values()]

    by_name: Dict[str, List[SkillCandidate]] = defaultdict(list)
    for cand in chosen:
        by_name[normalize_name(cand.name)].append(cand)

    return [choose_best(group) for group in by_name.values()]


def parse_difficulty(domain: str) -> Tuple[str, str]:
    if domain in {"security_compliance", "legal_contracts", "finance_analytics"}:
        return "Advanced", "â­â­â­"
    if domain in {"app_development", "technical_review", "web_development"}:
        return "Medium", "â­â­"
    return "Easy", "â­"


def domain_title(domain: str) -> str:
    return domain.replace("_", " ").title()


def ensure_domain_dir(domain: str) -> Path:
    path = SKILL_ROOT / domain
    path.mkdir(parents=True, exist_ok=True)
    return path


def domain_uses_numbers(domain_path: Path) -> bool:
    files = list(domain_path.glob("*.skill.md"))
    if not files:
        return False
    with_numbers = [f for f in files if re.match(r"^\\d+_", f.name)]
    return len(with_numbers) >= max(1, len(files) // 2)


def next_domain_index(domain_path: Path) -> int:
    indices = []
    for file in domain_path.glob("*.skill.md"):
        match = re.match(r"^(\\d+)_", file.name)
        if match:
            indices.append(int(match.group(1)))
    return max(indices) + 1 if indices else 1


def slugify(name: str) -> str:
    slug = normalize_name(name)
    return slug or "skill"


def base_slug_from_filename(filename: str) -> str:
    stem = filename.replace(".skill.md", "").replace(".skill", "")
    stem = re.sub(r"^\d+_", "", stem)
    stem = re.sub(r"_\d+$", "", stem)
    return stem


def description_score(text: str) -> int:
    match = re.search(r"##\s+ðŸŽ¯\s+Má»¥c Ä‘Ã­ch([\s\S]*?)(?=##\s+)", text)
    if match:
        return len(match.group(0))
    return len(text)


def pick_best_existing(paths: List[Path]) -> Path:
    def sort_key(path: Path) -> Tuple[int, int, int, str]:
        content = path.read_text(encoding="utf-8", errors="ignore")
        score = description_score(content)
        stem = path.stem.replace(".skill", "")
        suffix_match = re.search(r"_(\d+)$", stem)
        suffix = int(suffix_match.group(1)) if suffix_match else 0
        index_match = re.match(r"^(\d+)_", path.name)
        index = int(index_match.group(1)) if index_match else 999
        return (-score, suffix, index, path.name)

    return sorted(paths, key=sort_key)[0]


def pick_related_skills(domain_path: Path, exclude: str, limit: int = 2) -> List[Tuple[str, str]]:
    options = []
    for file in sorted(domain_path.glob("*.skill.md")):
        if file.name == exclude:
            continue
        title = extract_title(file)
        options.append((title, file.name))
    return options[:limit]


def extract_title(path: Path) -> str:
    for line in path.read_text(encoding="utf-8", errors="ignore").splitlines():
        if line.startswith("# "):
            return line.replace("# ", "").strip()
    return path.stem.replace(".skill", "").replace("_", " ").title()


def format_title(name: str) -> str:
    if not name:
        return "External Skill"
    words = re.split(r"[\\s_\\-]+", name.strip())
    return " ".join([w.capitalize() for w in words if w])


def normalize_text(text: str) -> str:
    return re.sub(r"\\s+", " ", text or "").strip()


def description_snippet(text: str, limit: int = 140) -> str:
    text = normalize_text(text)
    if not text:
        return ""
    for sep in [". ", "; ", " - ", " â€” "]:
        if sep in text:
            text = text.split(sep, 1)[0].strip()
            break
    if len(text) > limit:
        text = text[:limit].rsplit(" ", 1)[0].strip() + "..."
    return text


def matched_query_hint(query: str) -> str:
    query = (query or "").strip()
    if not query:
        return ""
    return f"- Keyword focus: {query}"


def render_skill_content(candidate: SkillCandidate, filename: str, related: List[Tuple[str, str]]) -> str:
    difficulty_label, difficulty_stars = parse_difficulty(candidate.cvf_domain)
    title = format_title(candidate.name)
    description = candidate.description.strip() or f"Skill há»— trá»£ {title} theo chuáº©n CVF."
    description = description.replace("\n", " ").strip()
    snippet = description_snippet(candidate.description)
    query_hint = matched_query_hint(candidate.matched_query)
    domain_example = DOMAIN_EXAMPLES.get(candidate.cvf_domain, {})
    example_objective = domain_example.get("objective") or f"{title} cho á»©ng dá»¥ng quáº£n lÃ½ cÃ´ng viá»‡c"
    example_context = domain_example.get("context") or snippet or f"Startup 5 ngÆ°á»i, cáº§n triá»ƒn khai {title.lower()} trong 3 tuáº§n"
    example_constraints = domain_example.get("constraints") or "KhÃ´ng Ä‘á»•i stack, Æ°u tiÃªn tá»‘c Ä‘á»™ triá»ƒn khai"
    findings = domain_example.get("findings") or []
    finding_1 = findings[0] if len(findings) > 0 else (snippet or "Quy trÃ¬nh hiá»‡n thiáº¿u bÆ°á»›c review rá»§i ro")
    finding_2 = findings[1] if len(findings) > 1 else f"ChÆ°a cÃ³ tiÃªu chÃ­ Ä‘o lÆ°á»ng thÃ nh cÃ´ng cho {title.lower()}"
    finding_3 = findings[2] if len(findings) > 2 else "Thiáº¿u checklist QA tá»‘i thiá»ƒu"

    related_lines = "\n".join([f"- [{title}](./{fname})" for title, fname in related]) or "- [App Requirements Spec](./01_app_requirements_spec.skill.md)"
    source_line = f"- Nguá»“n tham kháº£o: {candidate.source}" if candidate.source else "- Nguá»“n tham kháº£o: SkillsMP"
    uat_record = f"../../../governance/skill-library/uat/results/UAT-{slugify(candidate.name)}.md"
    risk_level = DOMAIN_RISK_MAP.get(candidate.cvf_domain, "R1")
    allowed_phases = DOMAIN_PHASES_MAP.get(candidate.cvf_domain, "Discovery, Design")
    autonomy = RISK_AUTONOMY.get(risk_level, "Human confirmation required")
    authority_scope = "Informational" if risk_level == "R0" else "Tactical" if risk_level in {"R1", "R2"} else "Strategic"

    return f"""# {title}

> **Domain:** {domain_title(candidate.cvf_domain)}  
> **Difficulty:** {difficulty_stars} {difficulty_label} â€” [Xem criteria](../DIFFICULTY_GUIDE.md)  
> **CVF Version:** v1.5.2  
> **Skill Version:** 1.0.0  
> **Last Updated:** {TODAY.isoformat()}

---

## ðŸ“Œ Prerequisites

KhÃ´ng yÃªu cáº§u báº¯t buá»™c. NÃªn chuáº©n bá»‹ bá»‘i cáº£nh ngáº¯n gá»n vá» dá»± Ã¡n Ä‘á»ƒ AI hiá»ƒu Ä‘Ãºng pháº¡m vi.

---

## ðŸŽ¯ Má»¥c Ä‘Ã­ch

> {description}

**Khi nÃ o dÃ¹ng skill nÃ y:**
- Cáº§n {title} vá»›i tiÃªu chÃ­ rÃµ rÃ ng
- Muá»‘n chuáº©n hÃ³a quy trÃ¬nh trÆ°á»›c khi thá»±c thi
- Muá»‘n Ä‘áº§u ra cÃ³ cáº¥u trÃºc, dá»… review

**KhÃ´ng phÃ¹ há»£p khi:**
- Thiáº¿u thÃ´ng tin Ä‘áº§u vÃ o tá»‘i thiá»ƒu
- Má»¥c tiÃªu Ä‘ang mÆ¡ há»“, chÆ°a thá»‘ng nháº¥t

---

## ðŸ›¡ï¸ Governance Summary (CVF Autonomous)

| Field | Value |
|-------|-------|
| Risk Level | {risk_level} |
| Allowed Roles | User, Reviewer |
| Allowed Phases | {allowed_phases} |
| Authority Scope | {authority_scope} |
| Autonomy | {autonomy} |
| Audit Hooks | Input completeness, Output structure, Scope guard |

---

## â›” Execution Constraints

- KhÃ´ng thá»±c thi ngoÃ i pháº¡m vi Ä‘Æ°á»£c khai bÃ¡o
- Tá»± Ä‘á»™ng dá»«ng náº¿u thiáº¿u input báº¯t buá»™c
- Vá»›i rá»§i ro {risk_level}: {autonomy.lower()}
- KhÃ´ng ghi/Ä‘á»•i dá»¯ liá»‡u há»‡ thá»‘ng náº¿u chÆ°a Ä‘Æ°á»£c xÃ¡c nháº­n

---

## âœ… Validation Hooks

- Check Ä‘á»§ input báº¯t buá»™c trÆ°á»›c khi báº¯t Ä‘áº§u
- Check output Ä‘Ãºng format Ä‘Ã£ Ä‘á»‹nh nghÄ©a
- Check khÃ´ng vÆ°á»£t scope vÃ  khÃ´ng táº¡o hÃ nh Ä‘á»™ng ngoÃ i yÃªu cáº§u
- Check output cÃ³ bÆ°á»›c tiáº¿p theo cá»¥ thá»ƒ

---

## ðŸ§ª UAT Binding

- Template: [AGENT_AI_UAT_CVF_TEMPLATE](../../../governance/skill-library/uat/AGENT_AI_UAT_CVF_TEMPLATE.md)
- UAT Record: [{slugify(candidate.name)}]({uat_record})
- UAT Objective: Skill pháº£i Ä‘áº¡t chuáº©n output theo CVF + khÃ´ng vÆ°á»£t quyá»n

---

## ðŸ“‹ Form Input

| Field | MÃ´ táº£ | Báº¯t buá»™c | VÃ­ dá»¥ |
|-------|-------|:--------:|-------|
| **Objective** | Má»¥c tiÃªu chÃ­nh | âœ… | "{title} cho sáº£n pháº©m SaaS nhá»" |
| **Context** | Bá»‘i cáº£nh dá»± Ã¡n | âœ… | "Team 3 ngÆ°á»i, deadline 2 tuáº§n" |
| **Constraints** | RÃ ng buá»™c ká»¹ thuáº­t | âœ… | "Chá»‰ dÃ¹ng stack hiá»‡n cÃ³" |
| **Input Data** | Dá»¯ liá»‡u liÃªn quan | âŒ | "Repo hiá»‡n táº¡i, tÃ i liá»‡u liÃªn quan" |
| **Output Format** | Äá»‹nh dáº¡ng mong muá»‘n | âŒ | "Checklist + Ä‘á» xuáº¥t" |

---

## âœ… Expected Output

**Káº¿t quáº£ báº¡n sáº½ nháº­n Ä‘Æ°á»£c:**

```markdown
# {title} Output

## Summary
- Goal: [Objective]
- Context: [Context]
- Constraints: [Constraints]

## Key Findings
1. [Finding 1]
2. [Finding 2]
3. [Finding 3]

## Recommendations
- [Recommendation 1]
- [Recommendation 2]

## Next Steps
- [Action 1]
- [Action 2]
```

---

## ðŸ” CÃ¡ch Ä‘Ã¡nh giÃ¡

**Checklist Accept/Reject:**

- [ ] Má»¥c tiÃªu rÃµ rÃ ng, bÃ¡m sÃ¡t bá»‘i cáº£nh
- [ ] Äáº§u ra cÃ³ cáº¥u trÃºc, dá»… hiá»ƒu
- [ ] CÃ³ khuyáº¿n nghá»‹ cá»¥ thá»ƒ, hÃ nh Ä‘á»™ng Ä‘Æ°á»£c
- [ ] KhÃ´ng vÆ°á»£t quÃ¡ pháº¡m vi yÃªu cáº§u

**Red flags (cáº§n Reject):**
- âš ï¸ Output chung chung, khÃ´ng actionable
- âš ï¸ Bá» qua constraints hoáº·c context
- âš ï¸ Tá»± Ã½ má»Ÿ rá»™ng scope

---

## âš ï¸ Common Failures

| Lá»—i thÆ°á»ng gáº·p | CÃ¡ch phÃ²ng trÃ¡nh |
|----------------|------------------|
| Thiáº¿u context | YÃªu cáº§u input tá»‘i thiá»ƒu trÆ°á»›c khi xá»­ lÃ½ |
| Output quÃ¡ dÃ i | TÃ³m táº¯t trÆ°á»›c, chi tiáº¿t sau |
| KhÃ´ng cÃ³ action | Báº¯t buá»™c Ä‘á» xuáº¥t bÆ°á»›c tiáº¿p theo |

---

## ðŸ’¡ Tips

- Æ¯u tiÃªn bá»‘i cáº£nh ngáº¯n, rÃµ, cÃ³ rÃ ng buá»™c
- ÄÆ°a ra 2-3 khuyáº¿n nghá»‹ kháº£ thi nháº¥t
- Náº¿u thiáº¿u dá»¯ liá»‡u, há»i láº¡i trÆ°á»›c khi tráº£ lá»i
{query_hint}
{source_line}

---

## ðŸ“Š VÃ­ dá»¥ thá»±c táº¿

**Input máº«u:**
```text
Objective: {example_objective}
Context: {example_context}
Constraints: {example_constraints}
Output Format: Checklist + Ä‘á» xuáº¥t
```

**Output máº«u:**
```markdown
# {title} Output

## Summary
- Goal: {example_objective}
- Context: {example_context}
- Constraints: {example_constraints}

## Key Findings
1. {finding_1}
2. {finding_2}
3. {finding_3}

## Recommendations
- Chuáº©n hÃ³a checklist triá»ƒn khai
- XÃ¡c Ä‘á»‹nh KPI trÆ°á»›c khi build

## Next Steps
- Thá»‘ng nháº¥t scope MVP
- Táº¡o checklist review láº§n 1
```

---

## ðŸ”— Related Skills

{related_lines}

---

## ðŸ”— Next Step

Ãp dá»¥ng output vÃ o káº¿ hoáº¡ch thá»±c thi hoáº·c chuyá»ƒn sang skill tiáº¿p theo trong domain.

---

## ðŸ“œ Version History

| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | {TODAY.isoformat()} | Initial CVF skill (imported from SkillsMP) |
"""


def write_skill(domain_path: Path, filename: str, content: str) -> None:
    path = domain_path / filename
    path.write_text(content, encoding="utf-8")


def build_candidates(raw_skills: List[Dict[str, object]]) -> List[SkillCandidate]:
    candidates = []
    for entry in raw_skills:
        name = str(entry.get("name") or "").strip() or "External Skill"
        description = str(entry.get("description") or "").strip()
        source = str(entry.get("source") or "").strip()
        cvf_domain = str(entry.get("cvf_domain") or "app_development").strip()
        score = float(entry.get("score") or 0)
        matched_query = str(entry.get("matched_query") or "")
        repo_key = str(entry.get("repo_key") or "") or repo_key_from_source(source)
        candidates.append(
            SkillCandidate(
                name=name,
                description=description,
                source=source,
                cvf_domain=cvf_domain,
                score=score,
                matched_query=matched_query,
                repo_key=repo_key,
                raw=entry,
            )
        )
    return candidates


def load_external_index() -> Dict[str, object]:
    if not EXTERNAL_INDEX_PATH.exists():
        return {"repos": {}}
    try:
        payload = json.loads(EXTERNAL_INDEX_PATH.read_text(encoding="utf-8"))
        if isinstance(payload, dict) and isinstance(payload.get("repos"), dict):
            return payload
    except json.JSONDecodeError:
        pass
    return {"repos": {}}


def update_external_imports(created: List[Tuple[SkillCandidate, str, str]]) -> None:
    index = load_external_index()
    repos = index.setdefault("repos", {})
    now = datetime.now(timezone.utc).isoformat()
    for cand, domain, filename in created:
        repo_key = cand.repo_key or external_key_for_skill(cand.source, cand.name)
        if not repo_key:
            continue
        entry = repos.get(repo_key) or {
            "sources": [],
            "names": [],
            "skillsmp_ids": [],
            "first_seen": now,
            "last_seen": now,
            "imported": False,
            "cvf_files": [],
            "source_types": ["skillsmp"],
            "best_score": 0,
            "best_desc_len": 0,
        }
        entry["imported"] = True
        entry["last_seen"] = now
        entry["last_imported"] = now
        if cand.source and cand.source not in entry["sources"]:
            entry["sources"].append(cand.source)
        if cand.name and cand.name not in entry["names"]:
            entry["names"].append(cand.name)
        if cand.raw.get("id") and cand.raw.get("id") not in entry["skillsmp_ids"]:
            entry["skillsmp_ids"].append(cand.raw.get("id"))
        cvf_file = f"{domain}/{filename}"
        if cvf_file not in entry["cvf_files"]:
            entry["cvf_files"].append(cvf_file)
        score = float(cand.score or 0)
        desc_len = len((cand.description or "").strip())
        if score > float(entry.get("best_score") or 0):
            entry["best_score"] = round(score, 2)
        if desc_len > int(entry.get("best_desc_len") or 0):
            entry["best_desc_len"] = desc_len
        repos[repo_key] = entry

    EXTERNAL_INDEX_PATH.parent.mkdir(parents=True, exist_ok=True)
    EXTERNAL_INDEX_PATH.write_text(json.dumps(index, ensure_ascii=False, indent=2), encoding="utf-8")


def main() -> int:
    parser = argparse.ArgumentParser(description="Convert SkillsMP shortlist to CVF skills.")
    parser.add_argument("--limit", type=int, default=50, help="Max skills to import.")
    parser.add_argument("--dry-run", action="store_true", help="Do not write files.")
    parser.add_argument("--refresh-template", action="store_true", help="Re-render existing files using the current template.")
    args = parser.parse_args()

    if not SHORTLIST_PATH.exists():
        raise SystemExit(f"Missing shortlist: {SHORTLIST_PATH}")

    raw_skills = load_shortlist(SHORTLIST_PATH)
    candidates = build_candidates(raw_skills)
    deduped = dedupe_candidates(candidates)
    deduped.sort(key=lambda x: x.score, reverse=True)
    selected = deduped[: args.limit]

    created = []
    existing_by_domain: Dict[Path, Dict[str, List[Path]]] = {}
    for cand in selected:
        domain_path = ensure_domain_dir(cand.cvf_domain)
        if domain_path not in existing_by_domain:
            existing_map: Dict[str, List[Path]] = defaultdict(list)
            for file in domain_path.glob("*.skill.md"):
                existing_map[base_slug_from_filename(file.name)].append(file)
            existing_by_domain[domain_path] = existing_map
        else:
            existing_map = existing_by_domain[domain_path]

        base_slug = slugify(cand.name)
        existing_matches = existing_map.get(base_slug, [])
        if existing_matches:
            best_existing = pick_best_existing(existing_matches)
            best_content = best_existing.read_text(encoding="utf-8", errors="ignore")
            should_update = args.refresh_template or len(cand.description or "") > description_score(best_content)
            if should_update:
                related = pick_related_skills(domain_path, best_existing.name)
                content = render_skill_content(cand, best_existing.name, related)
                if not args.dry_run:
                    write_skill(domain_path, best_existing.name, content)
            created.append((cand, domain_path.name, best_existing.name))
            continue

        use_numbers = domain_uses_numbers(domain_path)
        if use_numbers:
            index = next_domain_index(domain_path)
            filename_base = f"{index:02d}_{slugify(cand.name)}.skill.md"
        else:
            filename_base = f"{slugify(cand.name)}.skill.md"

        filename = filename_base

        related = pick_related_skills(domain_path, filename)
        content = render_skill_content(cand, filename, related)

        if not args.dry_run:
            write_skill(domain_path, filename, content)

        created.append((cand, domain_path.name, filename))
        existing_map.setdefault(base_slug, []).append(domain_path / filename)

    map_lines = [
        "# SkillsMP â†’ CVF Skill Import Map",
        "",
        f"> **Total Imported:** {len(created)}  ",
        f"> **Generated:** {TODAY.isoformat()}  ",
        "",
        "| # | CVF Domain | CVF File | Skill Name | Source | Query | Score |",
        "|---|------------|----------|------------|--------|-------|-------|",
    ]
    for idx, (cand, domain, filename) in enumerate(created, start=1):
        source = cand.source or "-"
        query = cand.matched_query or "-"
        map_lines.append(
            f"| {idx} | {domain} | {filename} | {cand.name} | {source} | {query} | {cand.score:.2f} |"
        )

    if not args.dry_run:
        MAP_OUTPUT.write_text("\n".join(map_lines) + "\n", encoding="utf-8")
        update_external_imports(created)

    print(f"Selected: {len(selected)}")
    print(f"Written: {len(created)}")
    print(f"Map: {MAP_OUTPUT}")
    return 0


if __name__ == "__main__":
    raise SystemExit(main())
